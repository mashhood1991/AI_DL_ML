{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python: Logistic Regression on Pima Indians Diabetes Database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>[1]. Introduction</h2>\n",
    "\n",
    "1. What Is Logistic Regression?\n",
    "\n",
    "   Logistic regression is one of the most popular machine learning algorithms for \"binary classification\" used in the Supervised Machine Learning technique. It can be extended when the dependent has more than two categories.\n",
    "   \n",
    "   Problems having binary outcomes, such as Yes/No, 0/1, True/False, are the ones being called binary classification problems.\n",
    "   \n",
    "   In logistic regression, we estimate an unknown probability for any given linear combination of independent variables.\n",
    "\n",
    "   \n",
    "   \n",
    "2. What are the applications of Logistic Regression?\n",
    "\n",
    "    Logistic regression can be applied anywhere that the outcome is binary. Some of the applications of logistic regression are:\n",
    "   1. Trying to figure out who will win the election\n",
    "   2. Whether an email is a spam.\n",
    "   3. Predicting whether a student will pass or not on the basis of hours of study or any relevant information.\n",
    "   4. Predicting the approval of loan on the basis of credit score.\n",
    "   5. Predicting the failure of a firm.\n",
    "   \n",
    "\n",
    "3. What are the terminology Used for Logistic Regression\n",
    "\n",
    "   1. Probability: Probability is the measure of the likelihood that an event will occur.Probability is quantified as a number between 0 and 1.\n",
    "   2. Odds: Odds is the ratio of the probability of occurring of an event and probability of not occurring such as odds = P(Occurring)/P(Not occurring) where P = Probability.\n",
    "   3. Odds ratio: Odds ratio for a variable in logistic regression that represents how the odds change with 1 unit increase in that variable holding all the other variables as constant. It can be defined as the ratio of two odds.\n",
    "   4. Logit: In logistic regression, we need a function that can link independent variables or map the linear combination of variables that could result in any value from 0 to 1. That function is called logit: ln(odds) = ln(p/1-p) = logit(p).\n",
    "\n",
    "\n",
    " \n",
    "4. Why Apply Logistic Regression?\n",
    "\n",
    "   Linear regression doesn’t give a good fit line for the problems having only two values(being shown in the figure), It will give less accuracy while prediction because it will fail to cover the datasets, being linear in nature.\n",
    "![linear_vs_logistic_regression](1_linear_vs_logistic_regression.jpg)\n",
    "\n",
    "    Linear Regression vs. Logistic Regression:\n",
    "\n",
    "    1. In linear regression, the outcome is continuous. It can have any one of an infinite number of possible values while In logistic regression, the outcome has only a limited number of possible values, generally 0 or 1.\n",
    "\n",
    "    2. Linear regression needs to establish the linear relationship between dependent and independent variable whereas it is not necessary for logistic regression.\n",
    "\n",
    "    3. In linear regression, the independent variables can be correlated with each other. On the contrary, in logistic regression, the variable must not be correlated with each other.\n",
    "\n",
    "5. What is the mathematics involved in logistic regression.\n",
    "   The main reason behind bending of the logistic regression  curve  is because of being calculated using a sigmoid function (also known as logistic function because being used in logistic regression)being given below:\n",
    "   \n",
    "   f(z) = 1/(1+e^(-z))\n",
    "\n",
    "   This is the mathematical function which is having the ‘S –  Shaped curve’.  The value of the sigmoid function always lies between 0 and 1, which is why it’s being deployed to solve categorical problems having two possible values.\n",
    "   \n",
    "   \n",
    "6. How to implement the logistic regression?\n",
    "\n",
    "   Logistic Regression deploys the sigmoid function to make predictions in the case of Categorical values.\n",
    "\n",
    "   It sets a cut-off point value, which is mostly being set as 0.5,  which, when being exceeded by the predicted output of the Logistic curve, gives respective predicted output in form of which category the dataset belongs\n",
    "\n",
    "   For Example,\n",
    "\n",
    "   In the case of the Diabetes prediction Model, if the output  exceeds the cutoff point,  prediction output will be given as Yes for  Diabetes otherwise No, if the value is below the cutoff point\n",
    "\n",
    "7. How to measure the performance of logistic regression?\n",
    "\n",
    "   For measuring the performance of the model solving classification problems, the Confusion matrix is being used.\n",
    "\n",
    "   Key terms:\n",
    "\n",
    "       – TN Stands for True Negatives(The predicted(negative) value matches the actual(negative) value)\n",
    "       – FP stands for False Positives (The actual value, was negative, but the model predicted a positive value)\n",
    "       – FN stands for False Negatives(The actual value, was positive, but the model predicted a negative value)\n",
    "       – TP stands for True Positives(The predicted(positive) value matched the actual value(positive))\n",
    "\n",
    "   For a good model, one should not have a high number of False Positive or  False Negative\n",
    "\n",
    " \n",
    "8. What are the key features of logistic regression?\n",
    "\n",
    "   1. It is used for predicting the categorical dependent variable, using a given set of independent variables.\n",
    "\n",
    "   2. It predicts the output of a categorical variable, which is discrete in nature. It can be either Yes or No, 0 or 1, true or False, etc. but instead of giving the exact value as 0 and 1, it gives the output as the probability of the dataset which lies between 0 and 1.\n",
    "\n",
    "   3. It is similar to Linear Regression. The only difference is that Linear Regression is used for solving regression problems, whereas Logistic regression is used for solving the classification problems/categorical problems.\n",
    "\n",
    "9. Types of Logistic Regression\n",
    "\n",
    "   There Are Three Types:\n",
    "\n",
    "   1. Binomial: Binomial Logistic regression deals with those problems with target variables having only two possible values, 0 or 1.\n",
    "      Which can Signify Yes/No, True /False, Dead/Alive, and other categorical values.\n",
    "   2. Ordinal:Ordinal Logistic Regression Deals with those problems whose target variables can have 3 or more than 3 values, unordered in nature. Those values don’t have any quantitative significance.\n",
    "      For Example Type 1 House, Type 3 House, Type 3 House, etc\n",
    "\n",
    "   3. Multinomial:Multinomial Logistic regression, just Ordinal Logistic Regression, deals with Problems having target values to be more than or equal to3. The main difference lies that unlike Ordinal, those values are well ordered. The values Hold Quantitative Significance.\n",
    "      For Example, Evaluation Of skill as Low, Average, Expert "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>[2]. Workflow for the logistic regression model</h2>\n",
    "\n",
    "1. Set learning rate and number of iterations (this will be done in __init__() function); initiate random weight and bias value (this will be done in fit() function). \n",
    "2. Build logistic regression function (sigmoid function).\n",
    "3. Update the parametrs using gradient descent algorithm in each iterations. Based on the number of iterations, we will finally get the best model (best weight and bias) as it has minimum cost.\n",
    "5. Finally, evaluate the model using prediction() function to determine the class of the dataset.\n",
    "\n",
    "<h3>Note:\n",
    "    \n",
    "    1. learning rate and number of iterations are called as the hyperparameters of the model because these are outside the model. They do not learn from the dataset!\n",
    "    \n",
    "    2. Weight and bias are called the parameters as their values are initialized with some random variables but gets updated during training phase of the model. They learn from the dataset!\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[2.1]. First of all, we import the dependencies</h3>\n",
    "\n",
    "We wiil use only numpy library for the implementation of logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports numpy library\n",
    "import numpy as np # to create arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[2.2]. Write code to build logistic regression model</h3>\n",
    "\n",
    "Create a class for the logistic regression algorithm. In this class we would need 4 functions:\n",
    "1. __init__(): function to initialize the parameters of the class.\n",
    "2. fit(): function to fit the dataset to our model, X and y of the training dataset wil be the parameters of the fit() function.\n",
    "3. update_weights(): function where we wil use the gradient descent to update the weights to get the optimal value of weights.\n",
    "4. predict(): function predicts the output on the test data after the model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a logistic regression class so you do not need to implement the logistic regression everytime you are using it!\n",
    "# The self parameter is a reference to the current instance of the class, and is used to access variables that belongs to the class.\n",
    "# self is always the first argument to any function of a class! \n",
    "class LogisticRegression():\n",
    "    \n",
    "    \n",
    "    # declares learning rate and number of iterations (hyperparameters)\n",
    "    def __init__(self, learning_rate, no_of_iterations): #initializes the parameters of the LogisticRegression class\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.no_of_iterations = no_of_iterations\n",
    "     \n",
    "    \n",
    "    # trains the model with dataset; X: feature matrix, and Y:target coloumn    \n",
    "    def fit(self, X, Y): #fits the train dataset to LogisticRegression model\n",
    "        \n",
    "        # here, first thing is to determine the number of number of data points and number of input features in your dataset\n",
    "        # number of data points in the dataset (number of rows) --> m\n",
    "        # number of input features in the dataset (number of coloumns) --> n\n",
    "        self.m, self.n = X.shape\n",
    "        \n",
    "        # m is needed to find the derivatives and n is needed to find the size of weight matrix\n",
    "        # initilizes weight and bias values\n",
    "        self.w = np.zeros(self.n) #numpy array with all the weight values related to each feature is set as 0\n",
    "        self.b = 0\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        # implementing gradient descent for optimization\n",
    "        # creates the gradient descent algorithm to update the weight and bias value\n",
    "        for i in range(self.no_of_iterations): #instead of no_of_iterations self.no_of_iterations made it successful!\n",
    "            self.update_weights()      \n",
    "    \n",
    "    # updates the weight and bias in each iteration\n",
    "    def update_weights(self, ): #updates the weight and bias to get get the optimal model\n",
    "        \n",
    "        # Y_hat value(sigmoid function)\n",
    "        # Y_hat = 1 / (1 + np.exp(-z))\n",
    "        Y_hat = 1 / (1 + np.exp(-(self.X.dot(self.w) + self.b))) #dot represents matrix multiplication\n",
    "        \n",
    "        # derivatives\n",
    "        dw = (1/self.m)*np.dot((self.X.T), (Y_hat - self.Y)) #T represnts the transpose of X is taken to match the matrix multuplication dimension rule\n",
    "        db = (1/self.m)*np.sum(Y_hat - self.Y)\n",
    "        \n",
    "        # update the weight and bias using gradient descent\n",
    "        self.w = self.w - self.learning_rate * dw\n",
    "        self.b = self.b - self.learning_rate * db\n",
    "        \n",
    "    \n",
    "    # write sigmoid equation and the decision boundary\n",
    "    def predict(self, X): #pridcits the y value on the test data after the model is trained\n",
    "        # if Y_predicted > 0.5 => y =1\n",
    "        # if Y_predicted < 0.5 => y =0\n",
    "        Y_pred = 1 / (1 + np.exp(-(X.dot(self.w) + self.b))) #here self.X is not required as we are predicting on X\n",
    "        \n",
    "        # converts the predicted decimal value to binary value\n",
    "        Y_pred = np.where(Y_pred > 0.5 , 1, 0) # if Y_pred > 0.5 => 1 else 0\n",
    "        \n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[2.3]. Train the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports dependencies to train the model\n",
    "import pandas as pd #to create DataFrame. DataFrame is a structural table\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collection and analysis\n",
    "# PIMA diabetes data\n",
    "# loading a diabetes dataset to a pandas DataFrame\n",
    "diabetes_dataset = pd.read_csv('data/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the first 5 rows of the dataset\n",
    "diabetes_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows and coloumns in the dataset\n",
    "diabetes_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets the statistical measures of the data\n",
    "diabetes_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tells how many target 0's and 1's\n",
    "diabetes_dataset['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: Non-diabatic = 500\n",
    "1: Diabetic = 268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.298000</td>\n",
       "      <td>109.980000</td>\n",
       "      <td>68.184000</td>\n",
       "      <td>19.664000</td>\n",
       "      <td>68.792000</td>\n",
       "      <td>30.304200</td>\n",
       "      <td>0.429734</td>\n",
       "      <td>31.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.865672</td>\n",
       "      <td>141.257463</td>\n",
       "      <td>70.824627</td>\n",
       "      <td>22.164179</td>\n",
       "      <td>100.335821</td>\n",
       "      <td>35.142537</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>37.067164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "Outcome                                                                      \n",
       "0           3.298000  109.980000      68.184000      19.664000   68.792000   \n",
       "1           4.865672  141.257463      70.824627      22.164179  100.335821   \n",
       "\n",
       "               BMI  DiabetesPedigreeFunction        Age  \n",
       "Outcome                                                  \n",
       "0        30.304200                  0.429734  31.190000  \n",
       "1        35.142537                  0.550500  37.067164  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groups the data based on their mean value\n",
    "diabetes_dataset.groupby('Outcome').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the data and lebels to get X and Y for training the model\n",
    "features = diabetes_dataset.drop(columns = 'Outcome', axis =1)\n",
    "target = diabetes_dataset['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  \n",
      "0                       0.627   50  \n",
      "1                       0.351   31  \n",
      "2                       0.672   32  \n",
      "3                       0.167   21  \n",
      "4                       2.288   33  \n",
      "..                        ...  ...  \n",
      "763                     0.171   63  \n",
      "764                     0.340   27  \n",
      "765                     0.245   30  \n",
      "766                     0.349   47  \n",
      "767                     0.315   23  \n",
      "\n",
      "[768 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "763    0\n",
      "764    0\n",
      "765    0\n",
      "766    1\n",
      "767    0\n",
      "Name: Outcome, Length: 768, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each feature data has different range of values, so standarizing is important to make them in similar range \n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_data = scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63994726  0.84832379  0.14964075 ...  0.20401277  0.46849198\n",
      "   1.4259954 ]\n",
      " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
      "  -0.19067191]\n",
      " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325546  0.60439732\n",
      "  -0.10558415]\n",
      " ...\n",
      " [ 0.3429808   0.00330087  0.14964075 ... -0.73518964 -0.68519336\n",
      "  -0.27575966]\n",
      " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
      "   1.17073215]\n",
      " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378505\n",
      "  -0.87137393]]\n"
     ]
    }
   ],
   "source": [
    "print(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = standardized_data\n",
    "target = diabetes_dataset['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63994726  0.84832379  0.14964075 ...  0.20401277  0.46849198\n",
      "   1.4259954 ]\n",
      " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
      "  -0.19067191]\n",
      " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325546  0.60439732\n",
      "  -0.10558415]\n",
      " ...\n",
      " [ 0.3429808   0.00330087  0.14964075 ... -0.73518964 -0.68519336\n",
      "  -0.27575966]\n",
      " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
      "   1.17073215]\n",
      " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378505\n",
      "  -0.87137393]]\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "763    0\n",
      "764    0\n",
      "765    0\n",
      "766    1\n",
      "767    0\n",
      "Name: Outcome, Length: 768, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test_size = 0.2: 20 % will go to test data and 80 % will go to train data\n",
    "# random_state = 2 whoever gives this, their data will be splitted in the similar way; used to reproduce the data exactly\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = 0.2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8) (614, 8) (154, 8)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiates an instance of the logistic regression class (or creates an object of the logistic regression class)\n",
    "# remember to pass all the parameters declared in the __init__() function of LogisticRegression class\n",
    "classifier = LogisticRegression(learning_rate = 0.01, no_of_iterations = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you can call the function of the logistic regression class on the created instance\n",
    "classifier.fit(x_train, y_train) #will go to logistic regression class and searches for fit() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[2.4]. Model Evaluation</h3>\n",
    "\n",
    "Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training data:  0.7768729641693811\n"
     ]
    }
   ],
   "source": [
    "# accuracy score on the training dat\n",
    "x_train_prediction = classifier.predict(x_train)\n",
    "training_data_accuracy = accuracy_score(y_train, x_train_prediction)\n",
    "print('Accuracy score on the training data: ', training_data_accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training data:  0.7662337662337663\n"
     ]
    }
   ],
   "source": [
    "# accuracy score on the test dat\n",
    "x_test_prediction = classifier.predict(x_test)\n",
    "test_data_accuracy = accuracy_score(y_test, x_test_prediction)\n",
    "print('Accuracy score on the training data: ', test_data_accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[2.5]. Making a predictive system</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3429808   1.41167241  0.14964075 -0.09637905  0.82661621 -0.78595734\n",
      "   0.34768723  1.51108316]]\n",
      "[1]\n",
      "The person is diabetic\n"
     ]
    }
   ],
   "source": [
    "input_data = (5,166,72,19,175,25.8,0.587,51)\n",
    "\n",
    "# changing the input_data to numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "# standardize the input data\n",
    "std_data = scaler.transform(input_data_reshaped)\n",
    "print(std_data)\n",
    "\n",
    "prediction = classifier.predict(std_data)\n",
    "print(prediction)\n",
    "\n",
    "if(prediction[0]==0):\n",
    "    print('The person is not diabetic')\n",
    "else:\n",
    "    print('The person is diabetic')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>[3]. References:</h2>\n",
    "\n",
    "[1]. https://dzone.com/articles/machinex-simplifying-logistic-regression\n",
    "\n",
    "[2]. https://www.analyticsvidhya.com/blog/2021/04/beginners-guide-to-logistic-regression-using-python/\n",
    "\n",
    "[3]. https://www.youtube.com/c/Siddhardhan/playlists\n",
    "\n",
    "[4]. https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.718281828459045\n",
      "148.4131591025766\n"
     ]
    }
   ],
   "source": [
    "#Mtahematical e value\n",
    "print(np.exp(1)) #e (2.718281828459045)\n",
    "print(np.exp(5)) #e^5 (148.4131591025766)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
